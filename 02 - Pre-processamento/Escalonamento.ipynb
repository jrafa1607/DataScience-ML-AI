{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeed76ac"
      },
      "source": [
        "## Standardization and Normalization in Machine Learning\n",
        "\n",
        "Standardization and normalization are data scaling techniques used to transform the values of numerical features in a dataset to a similar range. This is crucial for many machine learning algorithms that are sensitive to the scale of the input features, such as those based on distance calculations (e.g., K-Nearest Neighbors, Support Vector Machines with RBF kernel, and K-Means clustering).\n",
        "\n",
        "### Standardization (Z-score normalization)\n",
        "\n",
        "Standardization scales the data such that it has a mean of 0 and a standard deviation of 1. It is particularly useful when the data follows a Gaussian (normal) distribution, but it can also be applied to data that doesn't strictly follow a normal distribution.\n",
        "\n",
        "The formula for standardization is:\n",
        "\n",
        "## $x' = \\frac{x - \\mu}{\\sigma}$\n",
        "\n",
        "Where:\n",
        "- $x'$ is the standardized value.\n",
        "- $x$ is the original value.\n",
        "- $\\mu$ is the mean of the feature.\n",
        "- $\\sigma$ is the standard deviation of the feature.\n",
        "\n",
        "In your notebook, you used `sklearn.preprocessing.StandardScaler` to perform standardization on your data.\n",
        "\n",
        "### Normalization (Min-Max scaling)\n",
        "\n",
        "Normalization scales the data to a fixed range, usually between 0 and 1. This technique is useful when you need to bound the values within a specific range and when the data does not follow a Gaussian distribution.\n",
        "\n",
        "The formula for normalization is:\n",
        "\n",
        "## $x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n",
        "\n",
        "Where:\n",
        "- $x'$ is the normalized value.\n",
        "- $x$ is the original value.\n",
        "- $x_{min}$ is the minimum value of the feature.\n",
        "- $x_{max}$ is the maximum value of the feature.\n",
        "\n",
        "While you used standardization in your notebook, normalization is another common scaling technique you might encounter or use depending on the requirements of your machine learning model. In this notebook, you can use `sklearn.preprocessing.MinMaxScaler` for Min-Max scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ex1OdXmxPfxz"
      },
      "outputs": [],
      "source": [
        "#Import Libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Brtqa5Pfx0",
        "outputId": "e3417780-60ef-4098-86d4-09a3d5165c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      i#clientid        income        age         loan  c#default\n",
            "0              1  66155.925095  59.017015  8106.532131          0\n",
            "1              2  34415.153966  48.117153  6564.745018          0\n",
            "2              3  57317.170063  63.108049  8020.953296          0\n",
            "3              4  42709.534201  45.751972  6103.642260          0\n",
            "4              5  66952.688845  18.584336  8770.099235          1\n",
            "...          ...           ...        ...          ...        ...\n",
            "1995        1996  59221.044874  48.518179  1926.729397          0\n",
            "1996        1997  69516.127573  23.162104  3503.176156          0\n",
            "1997        1998  44311.449262  28.017167  5522.786693          1\n",
            "1998        1999  43756.056605  63.971796  1622.722598          0\n",
            "1999        2000  69436.579552  56.152617  7378.833599          0\n",
            "\n",
            "[2000 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#Read the Dataframe\n",
        "df = pd.read_csv('/content/credit_data.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BB5pZ9GuPfx1"
      },
      "outputs": [],
      "source": [
        "#Split the DataFrame (X) in Data and Classifier (Y)\n",
        "X = df.iloc[:,1:4].values\n",
        "Y = df.iloc[:, 4].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of Standardization with Scaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMsOaLqxRbgE",
        "outputId": "7667ed99-bb10-445e-b392-87dcdb09b45c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.45393393  1.33686061  1.20281942]\n",
            " [-0.76217555  0.53663921  0.69642695]\n",
            " [ 0.83682073  1.63720692  1.17471147]\n",
            " ...\n",
            " [-0.07122592 -0.93901609  0.35420081]\n",
            " [-0.11000289  1.7006195  -0.92675625]\n",
            " [ 1.682986    1.12656872  0.96381038]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Renew rhe Data\n",
        "X = df.iloc[:,1:4].values"
      ],
      "metadata": {
        "id": "9-7bZDO8SO4D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of Normalization with Scaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "X = scaler.fit_transform(X)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ol_WNgJRbZA",
        "outputId": "c7dfae3d-a248-486a-e4c8-2cfec29c0e92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9231759  0.95743135 0.58883739]\n",
            " [0.28812165 0.86378597 0.47682695]\n",
            " [0.74633429 0.99257918 0.58262011]\n",
            " ...\n",
            " [0.48612202 0.69109837 0.40112895]\n",
            " [0.47500998 1.         0.1177903 ]\n",
            " [0.98881367 0.93282208 0.53597028]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}