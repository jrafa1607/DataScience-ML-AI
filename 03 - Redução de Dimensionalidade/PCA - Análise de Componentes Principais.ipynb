{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7a0ed66"
      },
      "source": [
        "### PCA ( Principal Components Analasys ) + Mathematical Notation\n",
        "\n",
        "The goal of PCA is to find a set of orthogonal vectors (principal components) that capture the maximum variance in the data. Let $X$ be your data matrix with $n$ samples and $p$ features, where each row represents a sample and each column represents a feature.\n",
        "\n",
        "1.  **Mean Centering:** The first step is to center the data by subtracting the mean of each feature from the corresponding feature values.\n",
        "\n",
        "    $$X_{centered} = X - \\bar{X}$$\n",
        "    where $\\bar{X}$ is the mean vector of the features.\n",
        "\n",
        "2.  **Covariance Matrix:** Calculate the covariance matrix of the centered data.\n",
        "\n",
        "    $$\\Sigma = \\frac{1}{n-1} X_{centered}^T X_{centered}$$\n",
        "    The covariance matrix describes the relationships between the different features.\n",
        "\n",
        "\n",
        "3.  **Eigenvalue Decomposition:** Find the eigenvalues and eigenvectors of the covariance matrix $\\Sigma$.\n",
        "\n",
        "    $$\\Sigma v = \\lambda v$$\n",
        "    where $v$ is an eigenvector and $\\lambda$ is the corresponding eigenvalue. The eigenvectors represent the directions of maximum variance (the principal components), and the eigenvalues represent the magnitude of the variance along those directions.\n",
        "\n",
        "\n",
        "4.  **Sorting Eigenpairs:** Sort the eigenvectors in descending order based on their corresponding eigenvalues. The eigenvector with the largest eigenvalue is the first principal component, the eigenvector with the second largest eigenvalue is the second principal component, and so on.\n",
        "\n",
        "\n",
        "5.  **Selecting Principal Components:** Choose the top $k$ eigenvectors (principal components) that correspond to the largest eigenvalues. The number of components $k$ is typically chosen based on the desired amount of variance to retain or by looking at a scree plot.\n",
        "\n",
        "\n",
        "6.  **Projection:** Project the centered data onto the selected principal components to obtain the lower-dimensional representation of the data.\n",
        "    $$X_{projected} = X_{centered} W$$\n",
        "    where $W$ is the matrix formed by the top $k$ eigenvectors as columns."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA in `sklearn.decomposition.PCA`\n",
        "\n",
        "The `sklearn.decomposition.PCA` class in scikit-learn automates these steps.\n",
        "\n",
        "-   `PCA(n_components)`: Initializes a PCA object. `n_components` specifies the number of principal components to keep. If `n_components` is an integer, it specifies the exact number of components. If it's a float between 0 and 1, it specifies the proportion of variance to explain.\n",
        "-   `fit(X)`: Fits the PCA model to the data `X`. It calculates the mean, covariance matrix, eigenvalues, and eigenvectors.\n",
        "-   `transform(X)`: Projects the data `X` onto the principal components learned during the `fit` step.\n",
        "-   `fit_transform(X)`: Combines the `fit` and `transform` steps.\n",
        "\n",
        "After fitting, you can access attributes like:\n",
        "\n",
        "-   `components_`: The principal components (eigenvectors).\n",
        "-   `explained_variance_`: The amount of variance explained by each selected component (eigenvalues).\n",
        "-   `explained_variance_ratio_`: The percentage of variance explained by each selected component.\n",
        "\n",
        "The code you have already executed using `sklearn.decomposition.PCA` demonstrates these concepts by fitting a PCA model to your data and printing the principal components."
      ],
      "metadata": {
        "id": "BMDS8wl47V6z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dTWDNybk5-q2"
      },
      "outputs": [],
      "source": [
        "#import Libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVX2k0lv5-q4",
        "outputId": "d68d25f1-7f5c-45b2-8034-261041a38a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0              6      148             72             35        0  33.6   \n",
            "1              1       85             66             29        0  26.6   \n",
            "2              8      183             64              0        0  23.3   \n",
            "3              1       89             66             23       94  28.1   \n",
            "4              0      137             40             35      168  43.1   \n",
            "..           ...      ...            ...            ...      ...   ...   \n",
            "763           10      101             76             48      180  32.9   \n",
            "764            2      122             70             27        0  36.8   \n",
            "765            5      121             72             23      112  26.2   \n",
            "766            1      126             60              0        0  30.1   \n",
            "767            1       93             70             31        0  30.4   \n",
            "\n",
            "     DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                       0.627   50        1  \n",
            "1                       0.351   31        0  \n",
            "2                       0.672   32        1  \n",
            "3                       0.167   21        0  \n",
            "4                       2.288   33        1  \n",
            "..                        ...  ...      ...  \n",
            "763                     0.171   63        0  \n",
            "764                     0.340   27        0  \n",
            "765                     0.245   30        0  \n",
            "766                     0.349   47        1  \n",
            "767                     0.315   23        0  \n",
            "\n",
            "[768 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "#Read the DataFrame\n",
        "df = pd.read_csv('/content/diabetes_dataset.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for Negative Values in numeric columns\n",
        "numeric_cols = df.select_dtypes(include=np.number)\n",
        "print(numeric_cols.lt(0).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQKImj9e76zm",
        "outputId": "b7b2d9b4-7db6-4d60-9667-7e0317a525ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregnancies                 0\n",
            "Glucose                     0\n",
            "BloodPressure               0\n",
            "SkinThickness               0\n",
            "Insulin                     0\n",
            "BMI                         0\n",
            "DiabetesPedigreeFunction    0\n",
            "Age                         0\n",
            "Outcome                     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Null Values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "W_6rOlPm8UAX",
        "outputId": "892ed48d-2022-4ac9-ac95-565bc9498554"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pregnancies</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glucose</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BloodPressure</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SkinThickness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Insulin</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80a6ea67"
      },
      "source": [
        "### Factor Components for Dimensionality Reduction + Mathematical Notation\n",
        "\n",
        "In Factor Analysis, the **factor components** (also known as factor loadings) represent the relationship between the original observed variables and the underlying latent factors. These latent factors are the new, reduced set of dimensions that the model identifies.\n",
        "\n",
        "Let $X$ be the observed data matrix with $p$ variables and $n$ samples. Factor Analysis models the observed data as a linear combination of $k$ latent factors ($F$) and a unique error term ($\\epsilon$):\n",
        "\n",
        "$$X = \\Lambda F + \\epsilon$$\n",
        "\n",
        "where:\n",
        "- $X$ is the $p \\times n$ data matrix.\n",
        "- $\\Lambda$ is the $p \\times k$ matrix of **factor loadings** (the components we are discussing). Each element $\\lambda_{ij}$ represents the loading of the $i$-th observed variable on the $j$-th latent factor.\n",
        "- $F$ is the $k \\times n$ matrix of latent factor scores.\n",
        "- $\\epsilon$ is the $p \\times n$ matrix of unique error terms, representing the variance in $X$ not explained by the common factors.\n",
        "\n",
        "The process of using factor components for dimensionality reduction involves the following:\n",
        "\n",
        "1.  **Identifying Latent Factors:** Factor Analysis assumes that the correlations between observed variables can be explained by a smaller number of unobserved (latent) factors. The `fit()` method in `FactorAnalysis` estimates the factor loadings ($\\Lambda$) and the variances of the unique error terms ($\\Psi$, where $\\Psi$ is a diagonal matrix with the variances of $\\epsilon$ on the diagonal). The model aims to reproduce the observed covariance matrix ($\\Sigma$) with the estimated parameters:\n",
        "\n",
        "    $$\\Sigma \\approx \\Lambda \\Lambda^T + \\Psi$$\n",
        "\n",
        "2.  **Factor Loadings:** The `components_` attribute of the fitted `FactorAnalysis` object in scikit-learn corresponds to the matrix $\\Lambda$ of factor loadings. These loadings indicate how strongly each original variable is associated with each latent factor. High loadings suggest that a variable is a good indicator of that factor.\n",
        "\n",
        "3.  **Representing Data in Reduced Space:** Once the factors and their loadings are determined, you can transform the original data into the lower-dimensional space defined by these latent factors. This is typically done using the `transform()` method of the `FactorAnalysis` object, which estimates the factor scores ($F$) for each sample based on the observed data and the learned loadings.\n",
        "\n",
        "Essentially, Factor Analysis uses the factor components ($\\Lambda$) to understand the underlying structure of the data and then creates a new representation of the data (the factor scores $F$) based on these discovered latent factors, thereby achieving dimensionality reduction. Unlike PCA which focuses on maximizing variance, Factor Analysis aims to model the covariance structure of the observed variables using the latent factors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the Size of DataFrame\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kIOw34R8eQ5",
        "outputId": "c5781b40-fe37-46f1-cc22-8608f47ef790"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start the Factors And Inform the Desired Number of Components\n",
        "factors = FactorAnalysis(n_components=5).fit(df)"
      ],
      "metadata": {
        "id": "lO9neAbm8eOC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Factor Analysis and transform the data\n",
        "df_reduced_fa = factors.transform(df)"
      ],
      "metadata": {
        "id": "X9tg1E-2_kg_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape of the original and reduced DataFrames\n",
        "print(\"Original DataFrame shape:\", df.shape)\n",
        "print(\"Reduced DataFrame shape (Factor Analysis):\", df_reduced_fa.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh8-T4XiApHE",
        "outputId": "4dad6491-3a34-40b0-ef4c-e815aef6f29e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame shape: (768, 9)\n",
            "Reduced DataFrame shape (Factor Analysis): (768, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show the Reduced Dataframe\n",
        "df_reduced_fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuEwr_PDBFTm",
        "outputId": "f6fd5c37-1a07-43a0-f5af-e5298131654e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.66346898, -1.19776448, -0.15015341,  0.69874981,  1.82292907],\n",
              "       [-0.71225242,  0.92917876, -0.15605682, -0.08901717,  0.83392617],\n",
              "       [-0.64315095, -2.23589325,  0.81672604, -0.59968938, -0.95890383],\n",
              "       ...,\n",
              "       [ 0.27774039,  0.10284187, -0.11751162, -0.26989135, -0.11256013],\n",
              "       [-0.68703172, -0.45155179,  0.43664345,  1.34299119, -0.53382978],\n",
              "       [-0.70522896,  0.69143763, -0.23120526, -0.94407145,  0.67932666]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, a Example with PCA ( Initialize PCA with a number of components )\n",
        "pca = PCA(n_components=5)"
      ],
      "metadata": {
        "id": "jJ8JUYPvIhHs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit PCA on the DataFrame and transform the data\n",
        "df_reduced_pca = pca.fit_transform(df)"
      ],
      "metadata": {
        "id": "Y_RObEFVI3rN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape of the original and reduced DataFrames\n",
        "print(\"Original DataFrame shape:\", df.shape)\n",
        "print(\"Reduced DataFrame shape (PCA):\", df_reduced_pca.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-RHeuLNI8UL",
        "outputId": "1577548d-e1e5-4115-b825-189337469973"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame shape: (768, 9)\n",
            "Reduced DataFrame shape (PCA): (768, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show the Reduced Dataframe\n",
        "df_reduced_pca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k97YAkR7JAns",
        "outputId": "f36875a3-4e25-4d40-9e1d-fc5b0471234e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-75.71424916,  35.95494354,   7.26068338,  15.6705266 ,\n",
              "         16.50797757],\n",
              "       [-82.35846646, -28.90955895,   5.49664901,   9.00443012,\n",
              "          3.48038132],\n",
              "       [-74.63022933,  67.90963328, -19.46175322,  -5.65311372,\n",
              "        -10.29917609],\n",
              "       ...,\n",
              "       [ 32.11298721,  -3.37922193,   1.58797191,  -0.87945128,\n",
              "         -2.98161526],\n",
              "       [-80.21409513,  14.19059537, -12.35142227, -14.29252832,\n",
              "          8.53699105],\n",
              "       [-81.30834662, -21.6230423 ,   8.15277416,  13.82124771,\n",
              "         -4.91458328]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}